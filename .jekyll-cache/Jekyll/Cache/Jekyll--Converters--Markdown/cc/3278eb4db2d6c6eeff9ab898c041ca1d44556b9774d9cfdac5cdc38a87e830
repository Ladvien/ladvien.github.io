I"ú¦<p>This article is part of a series (linked above).  It will help explain the code used to train our convolutional neural-network (CNN) LEGO classifier.</p>

<p>If you want to follow with this article executing the code, weâ€™ve made it available in Googleâ€™s Colab:</p>

<ul>
  <li><a href="https://colab.research.google.com/drive/1b2_w2o60dMVJlV4Od25zTx2OUP07tdue">Lego Classifier</a></li>
</ul>

<h2 id="classifier-code">Classifier Code:</h2>
<p>The code below started with some we found on Kaggle:</p>

<ul>
  <li><a href="https://www.kaggle.com/twhitehurst3/lego-brick-images-keras-cnn-96-acc">Lego Brick Images Keras CCN</a></li>
</ul>

<p>However, there were <em>a lot</em> of problems in the code.  I rewrote most of it, so Iâ€™m not sure how much of the original is left.  Still, cite whatâ€™s not yours, I say.</p>

<p>Some of the issues were:</p>
<ul>
  <li>It used a model much more complex than needed.</li>
  <li>The code format was a mess.</li>
  <li>Mismatch of target output and loss.</li>
</ul>

<p>It was the last one which is <em>super</em> tricky, but critical.  Itâ€™s a hard to catch bug which will inaccurately report high accuracy.  Iâ€™ll discuss it more below, but itâ€™s a trap Iâ€™ve fallen into myself.</p>

<p>Regardless of the issues, it was good jump-starter code for us, since weâ€™ve never worked with a CNN.</p>

<p>Full code may be found here:</p>
<ul>
  <li><a href="https://github.com/Ladvien/lego_sorter/blob/master/lego_classifier_gpu.py">CNN LEGO Trainer (Python)</a></li>
</ul>

<h3 id="project-setup-local-only">Project Setup (local only)</h3>
<p>If you are running this code locally, you will need to do the following.</p>

<p>Enter the command prompt and navigate to your home directory.  Weâ€™re going to clone the project repository (repo), then, clone the data repo inside the project folder.</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/Ladvien/lego_sorter.git
cd lego_sorter
git clone https://github.com/Ladvien/lego_id_training_data.git
</code></pre></div></div>
<p>Then, open your Python IDE, set your directory to <code class="highlighter-rouge">./lego_sorter</code>, and open <code class="highlighter-rouge">lego_classifier_gpu.py</code>.</p>

<p>Lastly, if you see a cell like this:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">!</span>git clone https://github.com/Ladvien/lego_id_training_data.git
<span class="o">!</span><span class="nb">mkdir</span> ./data
<span class="o">!</span><span class="nb">mkdir</span> ./data/output
<span class="o">!</span><span class="nb">ls</span>
</code></pre></div></div>
<p>Skip or delete them, they are need when running the Colab notebook.</p>

<h3 id="classifier-code-needed-libraries">Classifier Code: Needed Libraries</h3>

<p>Below is the code used.  Looking over it again, I see some ways to clean it up, so know it may change in the future.</p>

<p>Hereâ€™s a breakdown of why the libraries are needed:</p>

<ul>
  <li><code class="highlighter-rouge">tensorflow</code> â€“ this is Googleâ€™s main deep-learning library, itâ€™s the heart of the project.</li>
  <li><code class="highlighter-rouge">keras</code> â€“ abstracts a lot of the details from creating a machine learning model.</li>
  <li><code class="highlighter-rouge">json</code> â€“ we write the classes to file for use later.</li>
  <li><code class="highlighter-rouge">tensorboard</code> â€“ visualizes your training session.</li>
  <li><code class="highlighter-rouge">webbrowser</code> â€“ this is opens your webrowser to tensorboard</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="c1"># Import needed tools.
</span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>

<span class="c1"># Import Keras
</span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">import</span> <span class="nn">tensorflow.keras</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span><span class="n">Flatten</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">Lambda</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">SeparableConv2D</span><span class="p">,</span> <span class="n">BatchNormalization</span><span class="p">,</span> <span class="n">MaxPooling2D</span><span class="p">,</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">Activation</span>
<span class="kn">from</span> <span class="nn">tensorflow.compat.v1.keras.preprocessing.image</span> <span class="kn">import</span> <span class="n">ImageDataGenerator</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.callbacks</span> <span class="kn">import</span> <span class="n">ModelCheckpoint</span><span class="p">,</span> <span class="n">EarlyStopping</span><span class="p">,</span> <span class="n">TensorBoard</span><span class="p">,</span> <span class="n">CSVLogger</span><span class="p">,</span> <span class="n">ReduceLROnPlateau</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing</span> <span class="kn">import</span> <span class="n">image</span>

<span class="c1"># Tensorboard
</span><span class="kn">from</span> <span class="nn">tensorboard</span> <span class="kn">import</span> <span class="n">program</span>
<span class="kn">import</span> <span class="nn">webbrowser</span>
<span class="kn">import</span> <span class="nn">time</span>
</code></pre></div></div>
<p>If you are following along with this code locally and need help setting up these libraries, just drop a comment below.  I got you.</p>

<h3 id="classifier-code-parameters">Classifier Code: Parameters</h3>
<p>The parameters sections is the heart of the training, Iâ€™ll highlight what each parameter is doing and then mention of some of the parameters you might want to tweak.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">continue_training</span>       <span class="o">=</span> <span class="bp">False</span>
<span class="n">initial_epoch</span>           <span class="o">=</span> <span class="mi">0</span>
<span class="n">clear_logs</span>              <span class="o">=</span> <span class="bp">True</span>

<span class="n">input_shape</span>             <span class="o">=</span> <span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="c1"># This is the shape of the image width, length, colors
</span><span class="n">image_size</span>              <span class="o">=</span> <span class="p">(</span><span class="n">input_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># DOH! image_size is (height, width)
</span><span class="n">train_test_ratio</span>        <span class="o">=</span> <span class="mf">0.2</span>
<span class="n">zoom_range</span>              <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">shear_range</span>             <span class="o">=</span> <span class="mf">0.1</span>

<span class="c1"># Hyperparameters
</span><span class="n">batch_size</span>              <span class="o">=</span> <span class="mi">16</span>
<span class="n">epochs</span>                  <span class="o">=</span> <span class="mi">40</span>
<span class="n">steps_per_epoch</span>         <span class="o">=</span> <span class="mi">400</span>
<span class="n">validation_steps</span>        <span class="o">=</span> <span class="mi">100</span> 
<span class="n">optimizer</span>               <span class="o">=</span> <span class="s">'adadelta'</span> 
<span class="n">learning_rate</span>           <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">val_save_step_num</span>       <span class="o">=</span> <span class="mi">1</span>

<span class="n">path_to_graphs</span>          <span class="o">=</span> <span class="s">'./data/output/logs/'</span>
<span class="n">model_save_dir</span>          <span class="o">=</span> <span class="s">'./data/output/'</span>
<span class="n">train_dir</span>               <span class="o">=</span> <span class="s">'./lego_id_training_data/gray_train/'</span>
<span class="n">val_dir</span>                 <span class="o">=</span> <span class="s">'./lego_id_training_data/gray_test/'</span>
</code></pre></div></div>
<h4 id="parameters-training-session">Parameters: Training Session</h4>
<p>These parameters help pick back up from an interrupted training session.  If your session is interrupted at epoch 183, then you could set <code class="highlighter-rouge">continue_training</code> = <code class="highlighter-rouge">True</code> and <code class="highlighter-rouge">initial_epoch</code> = 184, then execute the script.  This should then load the last best model and pick back up training where you left off.  Lastly, if you set <code class="highlighter-rouge">clear_logs</code> = <code class="highlighter-rouge">True</code> then it clears the Tensorboard information.  So, if you continue a session, you will want to set this to false.</p>

<p>This section is a WIP and there are several issues.  First, the Tensorboard logs should be save in separate folders and shouldnâ€™t need to be cleared.  Also, when continuing a training session it resets the best validation score (tracked for saving your model before overfitting) resulting in a temporary dip in performance.</p>

<h4 id="parameters-image-data">Parameters: Image Data</h4>
<p>The <code class="highlighter-rouge">input_shape</code> refers to the dimensions of an image: height, width, and color (RGB) values.  <code class="highlighter-rouge">image_size</code> derives from the <code class="highlighter-rouge">input_shape</code>.</p>

<p>Note, one issue I had early on with <code class="highlighter-rouge">image_size</code>.  I tried non-square images (which hurt training and arenâ€™t recommended) and found out the hard way most of the image parameters which are looking for height and width reverse their order in the Python libraries.</p>

<p>For example, this is whatâ€™s needed:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">...</span>
    <span class="n">val_dir</span><span class="p">,</span>
    <span class="n">target_size</span> <span class="o">=</span> <span class="p">(</span><span class="n">height_here</span><span class="p">,</span> <span class="n">width_here</span><span class="p">),</span>
<span class="o">...</span>
</code></pre></div></div>
<p>I was expecting:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">...</span>
    <span class="n">val_dir</span><span class="p">,</span>
    <span class="n">target_size</span> <span class="o">=</span> <span class="p">(</span><span class="n">width_here</span><span class="p">,</span> <span class="n">height_here</span><span class="p">),</span>
<span class="o">...</span>
</code></pre></div></div>
<p>It bit me, as most frameworks Iâ€™ve used expect width first and then heighth.  I mean, even when we talk about screen resolution we list width then height (e.g., <code class="highlighter-rouge">1920x1080</code>). Just be aware of it when using rectangle images.  Always RTFM (â€˜cause I donâ€™t).</p>

<p>The <code class="highlighter-rouge">train_test_ratio</code> controls how many images are held back.  Iâ€™d have to run through the code again, but I donâ€™t think this is needed.  As the preprocessing script has already create a folder with so many validation images.  Hmm, Iâ€™ll add it to my tech debt list.</p>

<p>The <code class="highlighter-rouge">zoom_range</code> parameter how far the script should zoom in on the images.  Latly, <code class="highlighter-rouge">shear_range</code> controls how much of the images to clip off the edges before feeding them to the CNN.</p>

<p><a href="https://ladvien.com/lego_classifier/batch.png"><img src="../images/lego_classifier/batch.png" alt="" class="float-right" /></a></p>
<h4 id="parameters-cnn-hyperparameters">Parameters: CNN Hyperparameters</h4>
<p>Hyperparameters is the term machine-learning (ML) engineers use to refer to parameters which can impact the training outcome of a neural net.</p>

<ul>
  <li><a href="https://towardsdatascience.com/what-are-hyperparameters-and-how-to-tune-the-hyperparameters-in-a-deep-neural-network-d0604917584a">What are Hyperparameters?</a></li>
</ul>

<p><code class="highlighter-rouge">batch_size</code> refers to the number of photos a neural-net should attempt to predict its class before updating the entire the weights of each <a href="https://towardsdatascience.com/what-the-hell-is-perceptron-626217814f53">perceptron</a>.</p>

<p><code class="highlighter-rouge">steps_per_epoch</code> are the number of batches to go through before considering one epoch complete. <code class="highlighter-rouge">epochs</code> is an arbitrary number representing how many <code class="highlighter-rouge">batches</code> * <code class="highlighter-rouge">steps_per_epoch</code> to go through before considering the training complete.</p>

<p>So, the length of training would go like this:</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>training schedule = epochs * steps_per_epoch * batch_size
</code></pre></div></div>

<p><code class="highlighter-rouge">validation_steps</code> is the number of batches from the training data to use for validating the current weights.  This will be used when we <code class="highlighter-rouge">fit</code> (train) our classifier and when we <code class="highlighter-rouge">evaluate</code> it.</p>

<p><code class="highlighter-rouge">optimizer</code> is the name of the optimizer used.  This is the heart of training, as it is what is responsible for updating the weights on each perceptron after each batch.</p>

<p>Iâ€™ve setup the code to only use one of two optimizers, either <code class="highlighter-rouge">adam</code> or <code class="highlighter-rouge">adagrad</code></p>

<p>Easy to read:</p>
<ul>
  <li><a href="https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/">Adam</a></li>
  <li><a href="https://databricks.com/glossary/adagrad">Adagrad</a></li>
</ul>

<p>Primary source:</p>
<ul>
  <li><a href="https://arxiv.org/abs/1412.6980">Adam</a></li>
  <li><a href="http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf">Adagrad</a></li>
</ul>

<p>The primary reason, as I understand it, to use <code class="highlighter-rouge">adagrad</code> over <code class="highlighter-rouge">adam</code>, is <code class="highlighter-rouge">adagrad</code>â€™s <code class="highlighter-rouge">learning_rate</code> will naturally modify itself to be more conducive to optimal convergence.</p>

<p>learning_rate           = 1.0</p>

<div style="clear: both;"></div>

<h1 id="hyperparameters">Hyperparameters</h1>

<p>val_save_step_num       = 1</p>

<h3 id="classifier-code-helper-functions">Classifier Code: Helper Functions</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="n">clear_logs</span><span class="p">:</span>
  <span class="err">!</span><span class="n">rm</span> <span class="o">-</span><span class="n">rf</span> <span class="n">data</span><span class="o">/</span><span class="n">output</span><span class="o">/</span><span class="n">logs</span><span class="o">/*</span>

<span class="k">def</span> <span class="nf">make_dir</span><span class="p">(</span><span class="n">dir_path</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">dir_path</span><span class="p">):</span>
        <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">dir_path</span><span class="p">)</span>
    

<span class="k">def</span> <span class="nf">show_final_history</span><span class="p">(</span><span class="n">history</span><span class="p">):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'loss'</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">epoch</span><span class="p">,</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s">'loss'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">'Train loss'</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">epoch</span><span class="p">,</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_loss'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">'Validation loss'</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'acc'</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">epoch</span><span class="p">,</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s">'acc'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">'Train acc'</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">epoch</span><span class="p">,</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_acc'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">'Validation acc'</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="classifier-code-data-preparation">Classifier Code: Data Preparation</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#################################
# Create needed dirs
#################################
</span><span class="n">make_dir</span><span class="p">(</span><span class="n">model_save_dir</span><span class="p">)</span>

<span class="c1">#################################
# Data generators
#################################
</span>
<span class="c1"># These Keras generators will pull files from disk
# and prepare them for training and validation.
</span><span class="n">augs_gen</span> <span class="o">=</span> <span class="n">ImageDataGenerator</span> <span class="p">(</span>
    <span class="n">shear_range</span> <span class="o">=</span> <span class="n">shear_range</span><span class="p">,</span>  
    <span class="n">zoom_range</span> <span class="o">=</span> <span class="n">shear_range</span><span class="p">,</span>        
    <span class="n">horizontal_flip</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span>
    <span class="n">validation_split</span> <span class="o">=</span> <span class="n">train_test_ratio</span>
<span class="p">)</span>  

<span class="n">train_gen</span> <span class="o">=</span> <span class="n">augs_gen</span><span class="o">.</span><span class="n">flow_from_directory</span> <span class="p">(</span>
    <span class="n">train_dir</span><span class="p">,</span>
    <span class="n">target_size</span> <span class="o">=</span> <span class="n">image_size</span><span class="p">,</span> <span class="c1"># THIS IS HEIGHT, WIDTH
</span>    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span><span class="p">,</span>
    <span class="n">class_mode</span> <span class="o">=</span> <span class="s">'sparse'</span><span class="p">,</span>
    <span class="n">shuffle</span> <span class="o">=</span> <span class="bp">True</span>
<span class="p">)</span>

<span class="n">test_gen</span> <span class="o">=</span> <span class="n">augs_gen</span><span class="o">.</span><span class="n">flow_from_directory</span> <span class="p">(</span>
    <span class="n">val_dir</span><span class="p">,</span>
    <span class="n">target_size</span> <span class="o">=</span> <span class="n">image_size</span><span class="p">,</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span><span class="p">,</span>
    <span class="n">class_mode</span> <span class="o">=</span> <span class="s">'sparse'</span><span class="p">,</span>
    <span class="n">shuffle</span> <span class="o">=</span> <span class="bp">False</span>
<span class="p">)</span>

<span class="c1">#################################
# Save Class IDs
#################################
</span><span class="n">classes_json</span> <span class="o">=</span> <span class="n">train_gen</span><span class="o">.</span><span class="n">class_indices</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_gen</span><span class="o">.</span><span class="n">class_indices</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="classifier-code-building-the-model">Classifier Code: Building the Model</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="k">def</span> <span class="nf">test_model</span><span class="p">(</span><span class="n">opt</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">input_shape</span> <span class="o">=</span> <span class="n">input_shape</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s">'relu'</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s">'relu'</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s">'relu'</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>  <span class="c1"># this converts our 3D feature maps to 1D feature vectors
</span>    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s">'relu'</span><span class="p">))</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s">'softmax'</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">model</span>

<span class="c1">#################################
# Create model
#################################
</span>
<span class="k">def</span> <span class="nf">get_optimizer</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">optimizer</span> <span class="o">==</span> <span class="s">'adam'</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">lr</span> <span class="o">=</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">beta_1</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span> <span class="n">beta_2</span> <span class="o">=</span> <span class="mf">0.999</span><span class="p">,</span> <span class="n">epsilon</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">decay</span> <span class="o">=</span> <span class="mf">0.</span><span class="p">,</span> <span class="n">amsgrad</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">optimizer</span> <span class="o">==</span> <span class="s">'sgd'</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span> <span class="o">=</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">momentum</span> <span class="o">=</span> <span class="mf">0.99</span><span class="p">)</span> 
    <span class="k">elif</span> <span class="n">optimizer</span> <span class="o">==</span> <span class="s">'adadelta'</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adadelta</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">rho</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">decay</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>

<span class="n">selected_optimizer</span> <span class="o">=</span> <span class="n">get_optimizer</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">test_model</span><span class="p">(</span><span class="n">selected_optimizer</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="nb">compile</span><span class="p">(</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="s">'sparse_categorical_crossentropy'</span><span class="p">,</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">selected_optimizer</span><span class="p">,</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s">'accuracy'</span><span class="p">]</span>
<span class="p">)</span>
</code></pre></div></div>

<h3 id="classifier-code-creating-callbacks">Classifier Code: Creating Callbacks</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">best_model_weights</span> <span class="o">=</span> <span class="n">model_save_dir</span> <span class="o">+</span> <span class="s">'base.model'</span>

<span class="n">checkpoint</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span>
    <span class="n">best_model_weights</span><span class="p">,</span>
    <span class="n">monitor</span> <span class="o">=</span> <span class="s">'val_loss'</span><span class="p">,</span>
    <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">save_best_only</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span>
    <span class="n">mode</span> <span class="o">=</span> <span class="s">'min'</span><span class="p">,</span>
    <span class="n">save_weights_only</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
    <span class="n">period</span> <span class="o">=</span> <span class="n">val_save_step_num</span>
<span class="p">)</span>

<span class="n">earlystop</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span>
    <span class="n">monitor</span><span class="o">=</span><span class="s">'val_loss'</span><span class="p">,</span>
    <span class="n">min_delta</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
    <span class="n">patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">mode</span><span class="o">=</span><span class="s">'auto'</span>
<span class="p">)</span>

<span class="n">tensorboard</span> <span class="o">=</span> <span class="n">TensorBoard</span><span class="p">(</span>
    <span class="n">log_dir</span> <span class="o">=</span> <span class="n">model_save_dir</span> <span class="o">+</span> <span class="s">'/logs'</span><span class="p">,</span>
    <span class="n">histogram_freq</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">write_graph</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">write_grads</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">write_images</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">csvlogger</span> <span class="o">=</span> <span class="n">CSVLogger</span><span class="p">(</span>
    <span class="n">filename</span> <span class="o">=</span> <span class="n">model_save_dir</span> <span class="o">+</span> <span class="s">'training.csv'</span><span class="p">,</span>
    <span class="n">separator</span> <span class="o">=</span> <span class="s">','</span><span class="p">,</span>
    <span class="n">append</span> <span class="o">=</span> <span class="bp">False</span>
<span class="p">)</span>

<span class="nb">reduce</span> <span class="o">=</span> <span class="n">ReduceLROnPlateau</span><span class="p">(</span>
    <span class="n">monitor</span><span class="o">=</span><span class="s">'val_loss'</span><span class="p">,</span>
    <span class="n">factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">patience</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
    <span class="n">mode</span><span class="o">=</span><span class="s">'auto'</span><span class="p">,</span>
    <span class="n">cooldown</span><span class="o">=</span><span class="mi">1</span> 
<span class="p">)</span>

<span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">csvlogger</span><span class="p">,</span> <span class="n">tensorboard</span><span class="p">]</span>
</code></pre></div></div>

<h3 id="classifier-code-training">Classifier Code: Training</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="n">continue_training</span><span class="p">:</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">best_model_weights</span><span class="p">)</span>
    <span class="n">model_score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate_generator</span><span class="p">(</span><span class="n">test_gen</span><span class="p">,</span> <span class="n">steps</span> <span class="o">=</span> <span class="n">validation_steps</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s">'Model Test Loss:'</span><span class="p">,</span> <span class="n">model_score</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Model Test Accuracy:'</span><span class="p">,</span> <span class="n">model_score</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>


<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit_generator</span><span class="p">(</span>
    <span class="n">train_gen</span><span class="p">,</span> 
    <span class="n">steps_per_epoch</span>  <span class="o">=</span> <span class="n">steps_per_epoch</span><span class="p">,</span> 
    <span class="n">validation_data</span>  <span class="o">=</span> <span class="n">test_gen</span><span class="p">,</span>
    <span class="n">validation_steps</span> <span class="o">=</span> <span class="n">validation_steps</span><span class="p">,</span>
    <span class="n">epochs</span> <span class="o">=</span> <span class="n">epochs</span><span class="p">,</span> 
    <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="n">callbacks</span>
<span class="p">)</span>
</code></pre></div></div>
:ET