I";Æ<p>This article is part of a series.  It should explain the code used to train our convolutional neural-network (CNN) LEGO classifier.</p>

<p>If you want to code along with this article, we‚Äôve made it available in Google‚Äôs Colab:</p>

<ul>
  <li><a href="https://colab.research.google.com/drive/1gD51CXRngVZhTO9464aFKHV2pejsVPcx">Lego Classifier</a></li>
</ul>

<p>Or if you want to run the code locally:</p>

<ul>
  <li><a href="https://github.com/Ladvien/lego_sorter">lego_sorter</a></li>
</ul>

<p>It‚Äôs a WIP, so comment below if you run into any issues.</p>

<h2 id="classifier-code">Classifier Code:</h2>
<p>Our code started with a notebook found on Kaggle:</p>

<ul>
  <li><a href="https://www.kaggle.com/twhitehurst3/lego-brick-images-keras-cnn-96-acc">Lego Brick Images Keras CCN</a></li>
</ul>

<p>However, there was <em>a lot</em> of problems in the code.  I rewrote most of it, so I‚Äôm not sure how much of the original is left.  Still, cite your sources!</p>

<p>Some of the issues were:</p>
<ul>
  <li>It used a model more complex than needed.</li>
  <li>The code format was a mess.</li>
  <li>Mismatch of target output and loss.</li>
</ul>

<p>It was the last one which is <em>super</em> tricky, but critical.  It‚Äôs a hard to catch bug which will inaccurately report high accuracy.  I‚Äôll discuss it more below, but it‚Äôs a trap I‚Äôve fallen into myself. Regardless of the issues, it was good jump-starter code, since we‚Äôve never worked with a CNN.</p>

<h3 id="project-setup-local-only">Project Setup (local only)</h3>
<p>If you are running this code locally, you will need to do the following.</p>

<p>Enter the command prompt and navigate to your home directory.  We‚Äôre going to clone the project repository (repo), then, clone the data repo inside the project folder.</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/Ladvien/lego_sorter.git
cd lego_sorter
git clone https://github.com/Ladvien/lego_id_training_data.git
</code></pre></div></div>
<p>Then, open your Python IDE, set your directory to <code class="highlighter-rouge">./lego_sorter</code>, and open <code class="highlighter-rouge">lego_classifier_gpu.py</code>.</p>

<p>Lastly, if you see a cell like this:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">!</span>git clone https://github.com/Ladvien/lego_id_training_data.git
<span class="o">!</span><span class="nb">mkdir</span> ./data
<span class="o">!</span><span class="nb">mkdir</span> ./data/output
<span class="o">!</span><span class="nb">ls</span>
</code></pre></div></div>
<p>Skip or delete them, they are need when running the Colab notebook.</p>

<h3 id="classifier-code-needed-libraries">Classifier Code: Needed Libraries</h3>

<p>Below is the code used.  Looking over it again, I see some ways to clean it up, so know it may change in the future.</p>

<p>Here‚Äôs a breakdown of why the libraries are needed:</p>

<ul>
  <li><code class="highlighter-rouge">tensorflow</code> ‚Äì Google‚Äôs main deep-learning library, it‚Äôs the heart of the project.</li>
  <li><code class="highlighter-rouge">keras</code> ‚Äì a library abstracting a lot of the details from creating a machine learning model.</li>
  <li><code class="highlighter-rouge">json</code> ‚Äì we write the classes to file for use later.</li>
  <li><code class="highlighter-rouge">tensorboard</code> ‚Äì a library for visualizing your training session.</li>
  <li><code class="highlighter-rouge">webbrowser</code> ‚Äì this is opens your webrowser to Tensorboard.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="c1"># Import needed tools.
</span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>

<span class="c1"># Import Keras
</span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">import</span> <span class="nn">tensorflow.keras</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span><span class="n">Flatten</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">Lambda</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">SeparableConv2D</span><span class="p">,</span> <span class="n">BatchNormalization</span><span class="p">,</span> <span class="n">MaxPooling2D</span><span class="p">,</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">Activation</span>
<span class="kn">from</span> <span class="nn">tensorflow.compat.v1.keras.preprocessing.image</span> <span class="kn">import</span> <span class="n">ImageDataGenerator</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.callbacks</span> <span class="kn">import</span> <span class="n">ModelCheckpoint</span><span class="p">,</span> <span class="n">EarlyStopping</span><span class="p">,</span> <span class="n">TensorBoard</span><span class="p">,</span> <span class="n">CSVLogger</span><span class="p">,</span> <span class="n">ReduceLROnPlateau</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing</span> <span class="kn">import</span> <span class="n">image</span>

<span class="c1"># Tensorboard
</span><span class="kn">from</span> <span class="nn">tensorboard</span> <span class="kn">import</span> <span class="n">program</span>
<span class="kn">import</span> <span class="nn">webbrowser</span>
<span class="kn">import</span> <span class="nn">time</span>
</code></pre></div></div>
<p>If you are following along with this code locally and need help setting up these libraries, just drop a comment below.  I got you.</p>

<h3 id="classifier-code-parameters">Classifier Code: Parameters</h3>
<p>The parameters sections is the heart of the training, I‚Äôll highlight what each parameter is doing and point out the parameters you might want to tweak.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">continue_training</span>       <span class="o">=</span> <span class="bp">False</span>
<span class="n">initial_epoch</span>           <span class="o">=</span> <span class="mi">0</span>
<span class="n">clear_logs</span>              <span class="o">=</span> <span class="bp">True</span>

<span class="n">input_shape</span>             <span class="o">=</span> <span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="c1"># This is the shape of the image width, length, colors
</span><span class="n">image_size</span>              <span class="o">=</span> <span class="p">(</span><span class="n">input_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># DOH! image_size is (height, width)
</span><span class="n">train_test_ratio</span>        <span class="o">=</span> <span class="mf">0.2</span>
<span class="n">zoom_range</span>              <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">shear_range</span>             <span class="o">=</span> <span class="mf">0.1</span>

<span class="c1"># Hyperparameters
</span><span class="n">batch_size</span>              <span class="o">=</span> <span class="mi">16</span>
<span class="n">epochs</span>                  <span class="o">=</span> <span class="mi">40</span>
<span class="n">steps_per_epoch</span>         <span class="o">=</span> <span class="mi">400</span>
<span class="n">validation_steps</span>        <span class="o">=</span> <span class="mi">100</span> 
<span class="n">optimizer</span>               <span class="o">=</span> <span class="s">'adadelta'</span> 
<span class="n">learning_rate</span>           <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">val_save_step_num</span>       <span class="o">=</span> <span class="mi">1</span>

<span class="n">path_to_graphs</span>          <span class="o">=</span> <span class="s">'./data/output/logs/'</span>
<span class="n">model_save_dir</span>          <span class="o">=</span> <span class="s">'./data/output/'</span>
<span class="n">train_dir</span>               <span class="o">=</span> <span class="s">'./lego_id_training_data/gray_train/'</span>
<span class="n">val_dir</span>                 <span class="o">=</span> <span class="s">'./lego_id_training_data/gray_test/'</span>
</code></pre></div></div>
<h4 id="parameters-training-session">Parameters: Training Session</h4>
<p>The first few parameters help continue from an interrupted training session.  For example, if your session is interrupted at epoch 183, then you could set <code class="highlighter-rouge">continue_training</code> = <code class="highlighter-rouge">True</code> and <code class="highlighter-rouge">initial_epoch</code> = 184, then execute the script.  This should then load the last best model and pick back up training where you left off.  Lastly, if you set <code class="highlighter-rouge">clear_logs</code> = <code class="highlighter-rouge">True</code> then it clears the Tensorboard information.  So, if you continue a session, you will want to set this to <code class="highlighter-rouge">False</code>.</p>

<p>This section is a WIP and there are several issues.  First, the Tensorboard logs should be saved in separate folders and shouldn‚Äôt need to be cleared.  Also, when continuing a training session it resets the best validation score (tracked for saving your model before overfitting) resulting in a temporary dip in performance.</p>

<h4 id="parameters-image-data">Parameters: Image Data</h4>
<p>The <code class="highlighter-rouge">input_shape</code> refers to the dimensions of an image: height, width, and color (RGB) values.  <code class="highlighter-rouge">image_size</code> comes from the <code class="highlighter-rouge">input_shape</code>.</p>

<p>Note, one issue I had early on with <code class="highlighter-rouge">image_size</code>.  I tried non-square images (which hurt training and aren‚Äôt recommended for CNNs) and found the hard way most of the image parameters for width and height reverse their order.</p>

<p>For example, this is what‚Äôs needed:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">...</span>
    <span class="n">val_dir</span><span class="p">,</span>
    <span class="n">target_size</span> <span class="o">=</span> <span class="p">(</span><span class="n">height_here</span><span class="p">,</span> <span class="n">width_here</span><span class="p">),</span>
<span class="o">...</span>
</code></pre></div></div>
<p>I was expecting:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">...</span>
    <span class="n">val_dir</span><span class="p">,</span>
    <span class="n">target_size</span> <span class="o">=</span> <span class="p">(</span><span class="n">width_here</span><span class="p">,</span> <span class="n">height_here</span><span class="p">),</span>
<span class="o">...</span>
</code></pre></div></div>
<p>It bit me hard, as most frameworks I‚Äôve used expect width first and then height.  I mean, even when we talk screen resolution we list width <em>then</em> height (e.g., <code class="highlighter-rouge">1920x1080</code>). Just be aware when using rectangle images.  Always RTFM (because, apparently, I didn‚Äôt).</p>

<p>The <code class="highlighter-rouge">train_test_ratio</code> controls how many images are held back for testing the model.  I‚Äôd have to run through the code again, but I don‚Äôt think this is needed.  As the preprocessing script already created a folder with a set number of validation images.  Hmm, I‚Äôll add it to my <a href="https://en.wikipedia.org/wiki/Technical_debt">tech debt</a> list.</p>

<p>The <code class="highlighter-rouge">zoom_range</code> parameter controls how far the script should zoom in on the images.  And, lastly, <code class="highlighter-rouge">shear_range</code> controls how much of the images to clip from the edges before feeding them to the CNN.</p>

<p><a href="https://ladvien.com/lego_classifier/batch.png"><img src="../images/lego_classifier/batch.png" alt="" class="float-right" /></a></p>
<h4 id="parameters-cnn-hyperparameters">Parameters: CNN Hyperparameters</h4>
<p>Hyperparameter is the term machine-learning (ML) engineers use to refer to parameters which can impact the training outcome of a neural net.</p>

<ul>
  <li><a href="https://towardsdatascience.com/what-are-hyperparameters-and-how-to-tune-the-hyperparameters-in-a-deep-neural-network-d0604917584a">What are Hyperparameters?</a></li>
</ul>

<p><code class="highlighter-rouge">batch_size</code> refers to the number of photos a neural-net should attempt to predict its class before updating the entire the weights of each <a href="https://towardsdatascience.com/what-the-hell-is-perceptron-626217814f53">perceptron</a>.  <strong>Note</strong>, the highest batch size is usually limited by your GPU RAM.  Locally, I use a <code class="highlighter-rouge">GTX 1060</code> with 6GB of RAM‚ÄìI couldn‚Äôt get a batch bigger than around 16.  YMMV.</p>

<p><code class="highlighter-rouge">steps_per_epoch</code> are the number of batches to go through before considering one epoch complete. <code class="highlighter-rouge">epochs</code> is an arbitrary number representing how many <code class="highlighter-rouge">batches</code> * <code class="highlighter-rouge">steps_per_epoch</code> to go through before considering the training complete.</p>

<p>So, the length of training would go like this: <code class="highlighter-rouge">training schedule = epochs * steps_per_epoch * batch_size</code></p>

<p><code class="highlighter-rouge">validation_steps</code> is the number of batches from the training data to use for validating the current weights.  This will be used when we <code class="highlighter-rouge">fit</code> (train) our classifier and when we <code class="highlighter-rouge">evaluate</code> it.</p>

<p><code class="highlighter-rouge">optimizer</code> is the name of the optimizer used.  This is the heart of training, as it is what is responsible for updating the weights on each perceptron after each batch.</p>

<p>I‚Äôve setup the code to only use one of three optimizers, either <code class="highlighter-rouge">adam</code>, <code class="highlighter-rouge">adagrad</code>, <code class="highlighter-rouge">sgd</code>.</p>

<p>Easy to read:</p>
<ul>
  <li><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">Stochastic Gradient Descent</a></li>
  <li><a href="https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/">Adam</a></li>
  <li><a href="https://databricks.com/glossary/adagrad">Adagrad</a></li>
</ul>

<p>Primary source:</p>
<ul>
  <li><a href="https://arxiv.org/abs/1412.6980">Adam</a></li>
  <li><a href="http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf">Adagrad</a></li>
</ul>

<p>The primary reason, as I understand it, to use <code class="highlighter-rouge">adagrad</code> over <code class="highlighter-rouge">adam</code>, is <code class="highlighter-rouge">adagrad</code>‚Äôs <code class="highlighter-rouge">learning_rate</code> will naturally modify itself to be more conducive to optimal convergence.</p>

<p>However, there are many optimizers.  A lot of them available in Keras:</p>

<ul>
  <li>Stochastic Gradient Descent (SGD)</li>
  <li>RMSprop</li>
  <li>Adagrad</li>
  <li>Adadelta</li>
  <li>Adam</li>
  <li>Nadam</li>
  <li>Adamax</li>
</ul>

<p>Keras‚Äô docs on optimizers:</p>

<ul>
  <li><a href="https://keras.io/optimizers/">Keras Optimizers</a></li>
</ul>

<p>The <code class="highlighter-rouge">learning_rate</code> controls how drastically the optimizer should change the perceptrons‚Äô weights when they have made an incorrect prediction.  Too high, it won‚Äôt converge (learn) too low and it will take a while.</p>

<p>You will find a lot of documentation saying, ‚ÄúThe default learning rate of an optimizer is best, it doesn‚Äôt need to be changed.‚Äù  I‚Äôve found this advice to be true, well, mostly.  I did run into an issue when using <code class="highlighter-rouge">adam</code>‚Äôs default setting of <code class="highlighter-rouge">0.001</code> in this project.  The neural-net just didn‚Äôt learn‚ÄìI had to drop it to around <code class="highlighter-rouge">0.0001</code>, which did better.</p>

<p>A starter read on learning rate:</p>

<ul>
  <li><a href="https://medium.com/octavian-ai/which-optimizer-and-learning-rate-should-i-use-for-deep-learning-5acb418f9b2">How to pick the best learning rate</a></li>
</ul>

<p>But! It‚Äôs not exhaustive, so if you interested in tweaking the optimizer or learning rate, Google and read as much as possible.</p>

<p>Lastly, <code class="highlighter-rouge">val_save_step_num</code> controls how many training epochs should pass before the validator tests whether your model is performing well on the test set.  The way we have teh code setup, if the validator says the model is performing better than any of the previous tests within this training session, then it will save the model automatically.</p>

<h3 id="classifier-code-data-preparation">Classifier Code: Data Preparation</h3>
<p>The <code class="highlighter-rouge">make_dir</code> allows making a directory, if it doesn‚Äôt already exist.  We then use it to create our model save directory.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">make_dir</span><span class="p">(</span><span class="n">dir_path</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">dir_path</span><span class="p">):</span>
        <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">dir_path</span><span class="p">)</span>

<span class="c1"># Create needed dirs
</span><span class="n">make_dir</span><span class="p">(</span><span class="n">model_save_dir</span><span class="p">)</span>
</code></pre></div></div>

<p>The next bit saves the classes the <code class="highlighter-rouge">train_gen</code> found to a file.  This is useful later when we are trying to quickly deploy the model to production.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Save Class IDs
</span><span class="n">classes_json</span> <span class="o">=</span> <span class="n">train_gen</span><span class="o">.</span><span class="n">class_indices</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_gen</span><span class="o">.</span><span class="n">class_indices</span><span class="p">)</span>
</code></pre></div></div>
<p>This saves one object to a <code class="highlighter-rouge">json</code> file.  The key (e.g., ‚Äú2456‚Äù) represents the code provided by LEGO.  And value is the numeric class assigned by the classifier.</p>
<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
    </span><span class="nl">"2456"</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w">
    </span><span class="nl">"3001"</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w">
    </span><span class="nl">"3002"</span><span class="p">:</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w">
    </span><span class="nl">"3003"</span><span class="p">:</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w">
    </span><span class="nl">"3004"</span><span class="p">:</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w">
    </span><span class="nl">"3010"</span><span class="p">:</span><span class="w"> </span><span class="mi">5</span><span class="p">,</span><span class="w">
    </span><span class="nl">"3039"</span><span class="p">:</span><span class="w"> </span><span class="mi">6</span><span class="p">,</span><span class="w">
    </span><span class="nl">"32064"</span><span class="p">:</span><span class="w"> </span><span class="mi">7</span><span class="p">,</span><span class="w">
    </span><span class="nl">"3660"</span><span class="p">:</span><span class="w"> </span><span class="mi">8</span><span class="p">,</span><span class="w">
    </span><span class="nl">"3701"</span><span class="p">:</span><span class="w"> </span><span class="mi">9</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>
<p>We can do the following later:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">predicted_lego_code</span> <span class="o">=</span> <span class="n">json_classes</span><span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">()]</span>
</code></pre></div></div>
<p>And the model will return the LEGO class it has identified.</p>

<h3 id="classifier-code-data-generator">Classifier Code: Data Generator</h3>
<p>When dealing with CNNs, often the input is much too large to fit all training into RAM (let alone GPU RAM) at once, which is the method preferred when dealing with tabular data.</p>

<p>Instead, a <code class="highlighter-rouge">DataGenarator</code> is used.  A <code class="highlighter-rouge">DataGenerator</code> is utility class provided by <code class="highlighter-rouge">Keras</code>, it loads training data in manageable chunks to feed to your training model.</p>

<p>First, we initialize <code class="highlighter-rouge">ImageDataGenerator</code> ‚Äì a subclass of <code class="highlighter-rouge">keras</code>‚Äô <code class="highlighter-rouge">DataGenerator</code>.  Then, we create two <code class="highlighter-rouge">flows</code>, one for loading data from the training folder into the model.  The other is the same, however, it loads data from the test folder for validating the model.</p>

<p>Let me annotate the parameters of the <code class="highlighter-rouge">ImageDataGenerator</code>:</p>
<ul>
  <li><code class="highlighter-rouge">shear_range</code> ‚Äì this controls how much of the images‚Äô edge is trimmed off as a percentage of the whole image.  This is useful for quickly reducing the size of images (thereby increasing training speed).</li>
  <li><code class="highlighter-rouge">zoom_range</code> ‚Äì is the how far to zoom on the image before feeding it to trainer or validator.</li>
  <li><code class="highlighter-rouge">horzinontal_flip</code> ‚Äì if this is set to <code class="highlighter-rouge">true</code>, the the images are randomly mirrored horizontally.  This essentially doubles your training images.</li>
  <li><code class="highlighter-rouge">validation_split</code> ‚Äì determines the percentage of images pulled for validation.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># These Keras generators will pull files from disk
# and prepare them for training and validation.
</span><span class="n">augs_gen</span> <span class="o">=</span> <span class="n">ImageDataGenerator</span> <span class="p">(</span>
    <span class="n">shear_range</span> <span class="o">=</span> <span class="n">shear_range</span><span class="p">,</span>  
    <span class="n">zoom_range</span> <span class="o">=</span> <span class="n">shear_range</span><span class="p">,</span>        
    <span class="n">horizontal_flip</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span>
    <span class="n">validation_split</span> <span class="o">=</span> <span class="n">train_test_ratio</span>
<span class="p">)</span>  
</code></pre></div></div>
<p>Now,the parameters of the <code class="highlighter-rouge">ImageDataGenerator.flow_from_directory</code> methods:</p>

<ul>
  <li><code class="highlighter-rouge">target_size</code> ‚Äì this one bit me.  It‚Äôs the size of your images as tuple (e.g., ‚Äú(150, 150)‚Äù).  <strong>It expects height <em>then</em> width.</strong></li>
  <li><code class="highlighter-rouge">batch_size</code> ‚Äì this is the number of images which will be loaded into the GPU RAM and trained on before updating the weights through back-propagation.</li>
  <li><code class="highlighter-rouge">class_mode</code> ‚Äì <strong>an import argument.</strong>  This sets up the targets for the model‚Äôs attempt at prediction.  <code class="highlighter-rouge">sparse</code> indicates the targets will look be <code class="highlighter-rouge">LabelEncoded</code>.</li>
</ul>

<p>If you have more than one class to predict, like us, you have two options.  Either <code class="highlighter-rouge">sparse</code> or <code class="highlighter-rouge">categorical</code>
<strong>Sparse</strong>
| target|
|:‚Äî‚Äì:|
| 1     |
| 2     |
| 3     |
| 2     |</p>

<p><strong>categorical</strong>
| 1|  2 | 3 |
|:‚Äì|:-:|‚Äì:|
| 1 | 0 | 0 |
| 0 | 1 | 0 |
| 0 | 0 | 1 |
| 0 | 1 | 0 |</p>

<p>DOn‚Äôt mix them up, or bad stuff happens.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_gen</span> <span class="o">=</span> <span class="n">augs_gen</span><span class="o">.</span><span class="n">flow_from_directory</span> <span class="p">(</span>
    <span class="n">train_dir</span><span class="p">,</span>
    <span class="n">target_size</span> <span class="o">=</span> <span class="n">image_size</span><span class="p">,</span> <span class="c1"># THIS IS HEIGHT, WIDTH
</span>    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span><span class="p">,</span>
    <span class="n">class_mode</span> <span class="o">=</span> <span class="s">'sparse'</span><span class="p">,</span>
    <span class="n">shuffle</span> <span class="o">=</span> <span class="bp">True</span>
<span class="p">)</span>

<span class="n">test_gen</span> <span class="o">=</span> <span class="n">augs_gen</span><span class="o">.</span><span class="n">flow_from_directory</span> <span class="p">(</span>
    <span class="n">val_dir</span><span class="p">,</span>
    <span class="n">target_size</span> <span class="o">=</span> <span class="n">image_size</span><span class="p">,</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span><span class="p">,</span>
    <span class="n">class_mode</span> <span class="o">=</span> <span class="s">'sparse'</span><span class="p">,</span>
    <span class="n">shuffle</span> <span class="o">=</span> <span class="bp">False</span>
<span class="p">)</span>

</code></pre></div></div>

<h3 id="classifier-code-building-the-model">Classifier Code: Building the Model</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="k">def</span> <span class="nf">test_model</span><span class="p">(</span><span class="n">opt</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">input_shape</span> <span class="o">=</span> <span class="n">input_shape</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s">'relu'</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s">'relu'</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s">'relu'</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>  <span class="c1"># this converts our 3D feature maps to 1D feature vectors
</span>    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s">'relu'</span><span class="p">))</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s">'softmax'</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">model</span>

<span class="c1">#################################
# Create model
#################################
</span>
<span class="k">def</span> <span class="nf">get_optimizer</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">optimizer</span> <span class="o">==</span> <span class="s">'adam'</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">lr</span> <span class="o">=</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">beta_1</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span> <span class="n">beta_2</span> <span class="o">=</span> <span class="mf">0.999</span><span class="p">,</span> <span class="n">epsilon</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">decay</span> <span class="o">=</span> <span class="mf">0.</span><span class="p">,</span> <span class="n">amsgrad</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">optimizer</span> <span class="o">==</span> <span class="s">'sgd'</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span> <span class="o">=</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">momentum</span> <span class="o">=</span> <span class="mf">0.99</span><span class="p">)</span> 
    <span class="k">elif</span> <span class="n">optimizer</span> <span class="o">==</span> <span class="s">'adadelta'</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adadelta</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">rho</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">decay</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>

<span class="n">selected_optimizer</span> <span class="o">=</span> <span class="n">get_optimizer</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">test_model</span><span class="p">(</span><span class="n">selected_optimizer</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="nb">compile</span><span class="p">(</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="s">'sparse_categorical_crossentropy'</span><span class="p">,</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">selected_optimizer</span><span class="p">,</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s">'accuracy'</span><span class="p">]</span>
<span class="p">)</span>
</code></pre></div></div>

<h3 id="classifier-code-creating-callbacks">Classifier Code: Creating Callbacks</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">best_model_weights</span> <span class="o">=</span> <span class="n">model_save_dir</span> <span class="o">+</span> <span class="s">'base.model'</span>

<span class="n">checkpoint</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span>
    <span class="n">best_model_weights</span><span class="p">,</span>
    <span class="n">monitor</span> <span class="o">=</span> <span class="s">'val_loss'</span><span class="p">,</span>
    <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">save_best_only</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span>
    <span class="n">mode</span> <span class="o">=</span> <span class="s">'min'</span><span class="p">,</span>
    <span class="n">save_weights_only</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
    <span class="n">period</span> <span class="o">=</span> <span class="n">val_save_step_num</span>
<span class="p">)</span>

<span class="n">tensorboard</span> <span class="o">=</span> <span class="n">TensorBoard</span><span class="p">(</span>
    <span class="n">log_dir</span> <span class="o">=</span> <span class="n">model_save_dir</span> <span class="o">+</span> <span class="s">'/logs'</span><span class="p">,</span>
    <span class="n">histogram_freq</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">write_graph</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">write_grads</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">write_images</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">tensorboard</span><span class="p">]</span>
</code></pre></div></div>

<h3 id="classifier-code-training">Classifier Code: Training</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="n">continue_training</span><span class="p">:</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">best_model_weights</span><span class="p">)</span>
    <span class="n">model_score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate_generator</span><span class="p">(</span><span class="n">test_gen</span><span class="p">,</span> <span class="n">steps</span> <span class="o">=</span> <span class="n">validation_steps</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s">'Model Test Loss:'</span><span class="p">,</span> <span class="n">model_score</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Model Test Accuracy:'</span><span class="p">,</span> <span class="n">model_score</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>


<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit_generator</span><span class="p">(</span>
    <span class="n">train_gen</span><span class="p">,</span> 
    <span class="n">steps_per_epoch</span>  <span class="o">=</span> <span class="n">steps_per_epoch</span><span class="p">,</span> 
    <span class="n">validation_data</span>  <span class="o">=</span> <span class="n">test_gen</span><span class="p">,</span>
    <span class="n">validation_steps</span> <span class="o">=</span> <span class="n">validation_steps</span><span class="p">,</span>
    <span class="n">epochs</span> <span class="o">=</span> <span class="n">epochs</span><span class="p">,</span> 
    <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="n">callbacks</span>
<span class="p">)</span>
</code></pre></div></div>
:ET